nohup: ignoring input
Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
/home/lenovo/alkestrup/venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:00,  8.28it/s]Downloading shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:00<00:00,  8.04it/s]Downloading shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:00<00:00,  7.16it/s]Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.38it/s]Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00,  7.48it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:05,  1.69s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.59s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.53s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.01it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:04<00:00,  1.21s/it]
Some weights of the model checkpoint at AI-Sweden-Models/Llama-3-8B-instruct were not used when initializing LlamaEncoderModel: ['lm_head.weight']
- This IS expected if you are initializing LlamaEncoderModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing LlamaEncoderModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Running Benchmark:   0%|          | 0/1 [00:00<?, ?it/s]Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps:   0%|          | 0/1 [00:00<?, ?it/s]
Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps:   0%|          | 0/12 [00:00<?, ?it/s][A
Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps on Angry Tweets:   0%|          | 0/12 [00:00<?, ?it/s][A
Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps on LCC:   0%|          | 0/12 [00:00<?, ?it/s]         [A
Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps on Bornholm Parallel:   0%|          | 0/12 [00:00<?, ?it/s][A
Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps on DKHate:   0%|          | 0/12 [00:00<?, ?it/s]           [A
Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps on Da Political Comments:   0%|          | 0/12 [00:00<?, ?it/s][A
Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps on DanFEVER:   0%|          | 0/12 [00:00<?, ?it/s]             [A
Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps on TV2Nord Retrieval:   0%|          | 0/12 [00:00<?, ?it/s][A
Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps on Twitterhjerne:   0%|          | 0/12 [00:00<?, ?it/s]    [A
Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps on Massive Intent:   0%|          | 0/12 [00:00<?, ?it/s][A
Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps on Massive Scenario:   0%|          | 0/12 [00:00<?, ?it/s][A
Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps on ScaLA:   0%|          | 0/12 [00:00<?, ?it/s]           [A
Running llama-8b-swe-llm2vec-supervised-wikigemma-100-steps on Language Identification:   0%|          | 0/12 [00:00<?, ?it/s][A
                                                                                                                              [ARunning llama-8b-swe-llm2vec-supervised-wikigemma-100-steps: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 837.86it/s]

Average results: 0.5624668091790892

Full Results:
[BenchmarkResults(meta=ModelMeta(name='llama-8b-swe-llm2vec-supervised-wikigemma-100-steps', description=None, huggingface_name='jealk/llm2vec-da-supervised-wiki-gemma', reference='https://huggingface.co/jealk/llm2vec-da-supervised-wiki-gemma', languages=['da'], open_source=False, embedding_size=4096, architecture=None, release_date=None), task_results=[TaskResult(task_name='Angry Tweets', task_description='A sentiment dataset with 3 classes (positiv, negativ, neutral) for Danish tweets', task_version='1.1.1', time_of_run=datetime.datetime(2024, 12, 7, 21, 45, 50, 154626), scores={'da': {'accuracy': 0.5731614135625598, 'f1': 0.5621521255167733, 'accuracy_stderr': 0.016562001165178718, 'f1_stderr': 0.016247880904538176, 'main_score': 0.5731614135625598}}, main_score='accuracy'), TaskResult(task_name='LCC', task_description='The leipzig corpora collection, annotated for sentiment', task_version='1.1.1', time_of_run=datetime.datetime(2024, 12, 7, 21, 46, 7, 312160), scores={'da': {'accuracy': 0.5973333333333335, 'f1': 0.5892651614890945, 'accuracy_stderr': 0.04846075158769667, 'f1_stderr': 0.044981698979431425, 'main_score': 0.5973333333333335}}, main_score='accuracy'), TaskResult(task_name='Bornholm Parallel', task_description='Danish Bornholmsk Parallel Corpus. Bornholmsk is a Danish dialect spoken on the island of Bornholm, Denmark. Historically it is a part of east Danish which was also spoken in Scania and Halland, Sweden.', task_version='1.1.1', time_of_run=datetime.datetime(2024, 12, 7, 21, 46, 20, 977236), scores={'da': {'precision': 0.08314636337714962, 'recall': 0.116, 'f1': 0.08969031548516843, 'accuracy': 0.116, 'main_score': 0.08969031548516843}, 'da-bornholm': {'precision': 0.08314636337714962, 'recall': 0.116, 'f1': 0.08969031548516843, 'accuracy': 0.116, 'main_score': 0.08969031548516843}}, main_score='f1'), TaskResult(task_name='DKHate', task_description='Danish Tweets annotated for Hate Speech either being Offensive or not', task_version='1.1.1', time_of_run=datetime.datetime(2024, 12, 7, 21, 46, 44, 143092), scores={'da': {'accuracy': 0.6580547112462005, 'f1': 0.5526122150992854, 'ap': 0.19505154820747644, 'accuracy_stderr': 0.06906120223405326, 'f1_stderr': 0.04662143694074912, 'ap_stderr': 0.023721883771790506, 'main_score': 0.6580547112462005}}, main_score='accuracy'), TaskResult(task_name='Da Political Comments', task_description='A dataset of Danish political comments rated for sentiment', task_version='1.1.1', time_of_run=datetime.datetime(2024, 12, 7, 21, 47, 22, 712437), scores={'da': {'accuracy': 0.3993340732519423, 'f1': 0.3673148294222574, 'accuracy_stderr': 0.02447551332630057, 'f1_stderr': 0.01617462137380054, 'main_score': 0.3993340732519423}}, main_score='accuracy'), TaskResult(task_name='DanFEVER', task_description='A Danish dataset intended for misinformation research. It follows the same format as the English FEVER dataset.', task_version='1.1.1', time_of_run=datetime.datetime(2024, 12, 7, 21, 48, 53, 808004), scores={'da': {'ndcg_at_1': 0.29609, 'ndcg_at_3': 0.35508, 'ndcg_at_5': 0.36492, 'ndcg_at_10': 0.37353, 'ndcg_at_100': 0.3805, 'ndcg_at_1000': 0.38139, 'map_at_1': 0.29601, 'map_at_3': 0.3411, 'map_at_5': 0.34661, 'map_at_10': 0.35024, 'map_at_100': 0.35183, 'map_at_1000': 0.35187, 'recall_at_1': 0.29601, 'recall_at_3': 0.39518, 'recall_at_5': 0.41888, 'recall_at_10': 0.44508, 'recall_at_100': 0.47607, 'recall_at_1000': 0.48298, 'precision_at_1': 0.29609, 'precision_at_3': 0.13181, 'precision_at_5': 0.08382, 'precision_at_10': 0.04455, 'precision_at_100': 0.00477, 'precision_at_1000': 0.00048, 'mrr_at_1': 0.29609, 'mrr_at_3': 0.34123, 'mrr_at_5': 0.34674, 'mrr_at_10': 0.35033, 'mrr_at_100': 0.35191, 'mrr_at_1000': 0.35195}}, main_score='ndcg_at_10'), TaskResult(task_name='TV2Nord Retrieval', task_description='News Article and corresponding summaries extracted from the Danish newspaper TV2 Nord.', task_version='1.1.1', time_of_run=datetime.datetime(2024, 12, 7, 21, 50, 57, 853435), scores={'da': {'ndcg_at_1': 0.66797, 'ndcg_at_3': 0.73779, 'ndcg_at_5': 0.75123, 'ndcg_at_10': 0.76843, 'ndcg_at_100': 0.78885, 'ndcg_at_1000': 0.79241, 'map_at_1': 0.66797, 'map_at_3': 0.72103, 'map_at_5': 0.72835, 'map_at_10': 0.73544, 'map_at_100': 0.73949, 'map_at_1000': 0.73964, 'recall_at_1': 0.66797, 'recall_at_3': 0.78613, 'recall_at_5': 0.81934, 'recall_at_10': 0.87256, 'recall_at_100': 0.96973, 'recall_at_1000': 0.99707, 'precision_at_1': 0.66797, 'precision_at_3': 0.26204, 'precision_at_5': 0.16387, 'precision_at_10': 0.08726, 'precision_at_100': 0.0097, 'precision_at_1000': 0.001, 'mrr_at_1': 0.66797, 'mrr_at_3': 0.72103, 'mrr_at_5': 0.72835, 'mrr_at_10': 0.73544, 'mrr_at_100': 0.73949, 'mrr_at_1000': 0.73964}}, main_score='ndcg_at_10'), TaskResult(task_name='Twitterhjerne', task_description="Danish question asked on Twitter with the Hashtag #Twitterhjerne ('Twitter brain') and their corresponding answer.", task_version='1.1.1', time_of_run=datetime.datetime(2024, 12, 7, 21, 51, 4, 633779), scores={'da': {'ndcg_at_1': 0.41026, 'ndcg_at_3': 0.35233, 'ndcg_at_5': 0.32985, 'ndcg_at_10': 0.37134, 'ndcg_at_100': 0.45899, 'ndcg_at_1000': 0.51336, 'map_at_1': 0.12778, 'map_at_3': 0.23009, 'map_at_5': 0.24921, 'map_at_10': 0.27881, 'map_at_100': 0.302, 'map_at_1000': 0.30669, 'recall_at_1': 0.12778, 'recall_at_3': 0.26902, 'recall_at_5': 0.30641, 'recall_at_10': 0.40278, 'recall_at_100': 0.70235, 'recall_at_1000': 0.98718, 'precision_at_1': 0.41026, 'precision_at_3': 0.30769, 'precision_at_5': 0.21538, 'precision_at_10': 0.13974, 'precision_at_100': 0.02449, 'precision_at_1000': 0.00336, 'mrr_at_1': 0.41026, 'mrr_at_3': 0.48718, 'mrr_at_5': 0.49231, 'mrr_at_10': 0.50044, 'mrr_at_100': 0.50993, 'mrr_at_1000': 0.51041}}, main_score='ndcg_at_10'), TaskResult(task_name='Massive Intent', task_description='MASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages', task_version='1.1.1', time_of_run=datetime.datetime(2024, 12, 7, 21, 55, 4, 856724), scores={'da': {'accuracy': 0.6749495628782785, 'f1': 0.630644830405299, 'accuracy_stderr': 0.009556825326923805, 'f1_stderr': 0.006233775380614438, 'main_score': 0.6749495628782785}, 'nb': {'accuracy': 0.6600874243443174, 'f1': 0.6142482142678375, 'accuracy_stderr': 0.016650498443396645, 'f1_stderr': 0.0128571885972809, 'main_score': 0.6600874243443174}, 'sv': {'accuracy': 0.6999663752521856, 'f1': 0.6559384744253671, 'accuracy_stderr': 0.011468996812163134, 'f1_stderr': 0.010672040983607448, 'main_score': 0.6999663752521856}}, main_score='accuracy'), TaskResult(task_name='Massive Scenario', task_description='MASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages', task_version='1.1.1', time_of_run=datetime.datetime(2024, 12, 7, 21, 56, 56, 888356), scores={'da': {'accuracy': 0.7340282447881641, 'f1': 0.7246541203461734, 'accuracy_stderr': 0.02439590739370147, 'f1_stderr': 0.019829966918057846, 'main_score': 0.7340282447881641}, 'nb': {'accuracy': 0.7094821788836584, 'f1': 0.7021491215055911, 'accuracy_stderr': 0.028590132655668843, 'f1_stderr': 0.025482537436285424, 'main_score': 0.7094821788836584}, 'sv': {'accuracy': 0.7532616005379961, 'f1': 0.7487738377133429, 'accuracy_stderr': 0.016856565994865624, 'f1_stderr': 0.0156259516963696, 'main_score': 0.7532616005379961}}, main_score='accuracy'), TaskResult(task_name='ScaLA', task_description='A linguistic acceptability task for Danish, Norwegian BokmÃ¥l Norwegian Nynorsk and Swedish.', task_version='1.1.1', time_of_run=datetime.datetime(2024, 12, 7, 21, 59, 30, 362072), scores={'da': {'accuracy': 0.609521484375, 'f1': 0.6053672570222478, 'ap': 0.5666979158852762, 'accuracy_stderr': 0.01987856476682159, 'f1_stderr': 0.019838106311968612, 'ap_stderr': 0.013711125808100836, 'main_score': 0.609521484375}, 'nb': {'accuracy': 0.590771484375, 'f1': 0.5884139483227372, 'ap': 0.5557778322720323, 'accuracy_stderr': 0.04074410804325551, 'f1_stderr': 0.040375953646809654, 'ap_stderr': 0.028703188461060597, 'main_score': 0.590771484375}, 'sv': {'accuracy': 0.621142578125, 'f1': 0.618411064351023, 'ap': 0.5774782966705512, 'accuracy_stderr': 0.025675841347226377, 'f1_stderr': 0.028466113191091876, 'ap_stderr': 0.018573268424290662, 'main_score': 0.621142578125}, 'nn': {'accuracy': 0.569775390625, 'f1': 0.5660397168224619, 'ap': 0.540542369392455, 'accuracy_stderr': 0.025892215401349738, 'f1_stderr': 0.02741189115903883, 'ap_stderr': 0.016660344135318465, 'main_score': 0.569775390625}}, main_score='accuracy'), TaskResult(task_name='Language Identification', task_description='A dataset for Nordic language identification.', task_version='1.1.1', time_of_run=datetime.datetime(2024, 12, 7, 22, 0, 33, 519170), scores={'da': {'accuracy': 0.9103333333333333, 'f1': 0.9100074798960405, 'accuracy_stderr': 0.0036666666666666757, 'f1_stderr': 0.0036412644388425864, 'main_score': 0.9103333333333333}, 'sv': {'accuracy': 0.9103333333333333, 'f1': 0.9100074798960405, 'accuracy_stderr': 0.0036666666666666757, 'f1_stderr': 0.0036412644388425864, 'main_score': 0.9103333333333333}, 'nb': {'accuracy': 0.9103333333333333, 'f1': 0.9100074798960405, 'accuracy_stderr': 0.0036666666666666757, 'f1_stderr': 0.0036412644388425864, 'main_score': 0.9103333333333333}, 'nn': {'accuracy': 0.9103333333333333, 'f1': 0.9100074798960405, 'accuracy_stderr': 0.0036666666666666757, 'f1_stderr': 0.0036412644388425864, 'main_score': 0.9103333333333333}, 'is': {'accuracy': 0.9103333333333333, 'f1': 0.9100074798960405, 'accuracy_stderr': 0.0036666666666666757, 'f1_stderr': 0.0036412644388425864, 'main_score': 0.9103333333333333}, 'fo': {'accuracy': 0.9103333333333333, 'f1': 0.9100074798960405, 'accuracy_stderr': 0.0036666666666666757, 'f1_stderr': 0.0036412644388425864, 'main_score': 0.9103333333333333}}, main_score='accuracy')])]
